# DeepSeek Crowley Magnet Link - Crawler Profissional

Este projeto cont√©m um crawler avan√ßado de links magn√©ticos, projetado para ser robusto, configur√°vel e eficiente. O script principal e recomendado para uso √© o `crawler_profissional.py`.

## üöÄ Script Principal: `crawler_profissional.py`

Este script √© a vers√£o unificada e aprimorada, combinando as melhores caracter√≠sticas dos scripts legados. Ele foi projetado para realizar uma busca completa e inteligente em m√∫ltiplos sites.

### Funcionalidades Principais

- **Busca em M√∫ltiplos Sites**: L√™ uma lista de sites do arquivo `base_busca.txt` para escanear.
- **Hist√≥rico Persistente**: Mant√©m um registro de todos os links j√° encontrados (`links-magnetic-download.txt`) para evitar a adi√ß√£o de duplicatas.
- **Detec√ß√£o de Novidades**: Ao re-escanear um site, ele identifica e salva apenas os links que ainda n√£o est√£o no hist√≥rico.
- **Varredura Profunda**: Navega por todas as p√°ginas internas de cada site para garantir uma busca completa.
- **Comportamento Configur√°vel**: Permite ajustar o n√∫mero de `threads` e `delays` para controlar a velocidade, podendo operar de forma lenta e cuidadosa ("como um humano") ou de forma r√°pida e agressiva.
- **Rastreamento √âtico**: Respeita as regras definidas no arquivo `robots.txt` de cada site.
- **Categoriza√ß√£o Autom√°tica**: Organiza os novos links encontrados em arquivos de texto separados por categoria (Filmes, S√©ries, Jogos, etc.), prontos para importa√ß√£o.

### Como Usar

1.  **Configure os Sites**: Abra o arquivo `base_busca.txt` e adicione a lista de sites que voc√™ deseja escanear (um site por linha).
2.  **Ajuste as Configura√ß√µes (Opcional)**: Abra o `crawler_profissional.py` e, no final do arquivo (dentro de `if __name__ == "__main__":`), voc√™ pode alterar as configura√ß√µes de `max_threads` e `delay_entre_requests` para se adequar √†s suas necessidades.
    *   `max_threads`: Para um comportamento mais lento e cuidadoso, use `1`. Para mais velocidade, aumente para `5` ou `10`.
    *   `delay_entre_requests`: Tempo em segundos entre cada requisi√ß√£o. √â recomendado manter em `1` ou mais para n√£o sobrecarregar os servidores dos sites.
3.  **Execute o Script**: Abra seu terminal e execute o comando:
    ```sh
    python crawler_profissional.py
    ```
4.  **Verifique os Resultados**: Ao final da execu√ß√£o, os novos links ser√£o salvos em:
    *   `links-novos.txt`: Cont√©m apenas os links encontrados na √∫ltima execu√ß√£o.
    *   `links-<categoria>.txt`: Arquivos separados para cada categoria (ex: `links-filmes.txt`).
    *   `links-magnetic-download.txt`: O arquivo com o hist√≥rico completo de todos os links j√° encontrados.

---

## Legacy Scripts (Vers√µes Antigas)

Os scripts a seguir foram usados para construir a vers√£o profissional e s√£o mantidos como refer√™ncia, mas **n√£o s√£o recomendados para uso regular**.

-   **`deepseek_1.py`**: Um crawler b√°sico de thread √∫nica para um √∫nico dom√≠nio.
-   **`deepseek.py`**: Um crawler multi-site com hist√≥rico e categoriza√ß√£o, mas com um motor de busca superficial.
-   **`deepseek_digite_site.py`**: Um crawler multi-thread r√°pido e profundo, mas apenas para um √∫nico site e sem hist√≥rico persistente.
